{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiLSTM_model.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNXVCAMZoD4juo9qyFTUTWj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wqJuM0-Jc8U_"},"source":["# Import Library\n"]},{"cell_type":"code","metadata":{"id":"Ql1NSWPSdAqL"},"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","import re\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8RyEeLci3jh"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5HVRr59rgrPz"},"source":["!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n","%cd Mecab-ko-for-Google-Colab\n","!bash install_mecab-ko_on_colab190912.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvZtAJH8ewf5"},"source":["import urllib.request\n","from collections import Counter\n","from konlpy.tag import Mecab\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNcRKTFs8JGE"},"source":["# !pip install kss\n","# import kss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTrMjxtMsUIn"},"source":["# !pip install imbalanced-learn\n","# !pip install -U scikit-learn\n","# !pip install -U imbalanced-learn\n","# !pip install delayed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-JNZyMnqdGdE"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qmXsqkNmdwYM"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"WFSwMUSqdaVC"},"source":["data = pd.read_csv(\"/content/drive/MyDrive/쿠아이 컨퍼런스/preprocessing_final1.csv\")\n","data.drop(['Unnamed: 0'], axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMzxVdrWd1XT"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qcsxNT20d2Xp"},"source":["# Preprocessing by input shape"]},{"cell_type":"code","metadata":{"id":"Q6LxDy1_ykX9"},"source":["# from imblearn.under_sampling import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcrJZGlgr6tf"},"source":["train_data, test_data = train_test_split(data, test_size = 0.2, random_state = 42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"McgBNvMgmSoY"},"source":["# 불용어 정의\n","stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '게임', '겜', '되', '음', '면']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZ-uu2a3qkhx"},"source":["mecab = Mecab() \n","\n","train_data['tokenized'] = train_data['content'].apply(mecab.morphs)\n","train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n","test_data['tokenized'] = test_data['content'].apply(mecab.morphs)\n","test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fcDgcjAQrc7J"},"source":["# train, test data split\n","\n","X_train = train_data['tokenized'].values\n","X_test= test_data['tokenized'].values\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFtW3GjOA3Vu"},"source":["label='f_t'\n","y_train = train_data[label].values\n","y_test = test_data[label].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbcokdKerveY"},"source":["# 정수 인코딩\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CVqoCdhcr3Wg"},"source":["threshold = 2\n","total_cnt = len(tokenizer.word_index) # 단어의 수\n","rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n","rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n","\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n","for key, value in tokenizer.word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('단어 집합(vocabulary)의 크기 :',total_cnt)\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9QKNVaQr7oR"},"source":["vocab_size = total_cnt - rare_cnt + 2\n","print('단어 집합의 크기 :',vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkcseO6FsDGB"},"source":["tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n","tokenizer.fit_on_texts(X_train)\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gK2-SPosJC_"},"source":["print(X_train[:3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eN0SkJuNsK_v"},"source":["# 패딩\n","print('content의 최대 길이 :',max(len(l) for l in X_train))\n","print('content의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n","plt.hist([len(s) for s in X_train], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04FkrDs4sSEH"},"source":["# 패딩으로 짤리는 데이터 확인용 함수\n","def below_threshold_len(max_len, nested_list):\n","  cnt = 0\n","  for s in nested_list:\n","    if(len(s) <= max_len):\n","        cnt = cnt + 1\n","  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kW5rvLYsgxu"},"source":["max_len = 256\n","below_threshold_len(max_len, X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Gp_A7OwsjLR"},"source":["X_train = pad_sequences(X_train, maxlen = max_len)\n","X_test = pad_sequences(X_test, maxlen = max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5XGxunFwibw_"},"source":["# 성능평가 함수"]},{"cell_type":"markdown","metadata":{"id":"st7QTj8Bst2R"},"source":["# 모델링"]},{"cell_type":"markdown","metadata":{"id":"hG8u-2ZzKd5o"},"source":["## version 1"]},{"cell_type":"code","metadata":{"id":"xNJlKzMSsxRZ"},"source":["from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FrfRx_e8sy-k"},"source":["model = Sequential()\n","model.add(Embedding(vocab_size, 128))\n","model.add(Bidirectional(LSTM(128)))\n","model.add(Dense(1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCB0UhTHs4-h"},"source":["es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=4)\n","mc = ModelCheckpoint('best_model1.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYvJZztts6aB"},"source":["model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n","history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=256, validation_split=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9EWSs1EVtKRr"},"source":["loaded_model1 = load_model('best_model1.h5')\n","predicted_version1=loaded_model1.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kY3vf-unpdUB"},"source":["p = []\n","for i in predicted_version1:\n","    if i >= 0.5:\n","        p.append(1)\n","    else:\n","        p.append(0)\n","print(classification_report(y_test, p, target_names=['class 0', 'class 1']))    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUJlnpRix360"},"source":["z = []\n","for i in predicted_version1:\n","    z.append(np.argmax(i))\n","print(classification_report(y_test, z, target_names=['class 0', 'class 1']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqEpr2S-y5DF"},"source":["plt.hist(predicted_version1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGoLRnEctNdo"},"source":["## version 2"]},{"cell_type":"code","metadata":{"id":"2hOVOaMBtFQH"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import csv\n","import random\n","import pickle\n","import collections\n","import tensorflow as tf\n","from keras.preprocessing.text import Tokenizer\n","from nltk import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","import joblib\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.models import Sequential\n","from keras.models import load_model\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Bidirectional\n","from keras.layers import GRU\n","from keras.layers import SimpleRNN\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","from keras.preprocessing import text\n","from tensorflow.keras.optimizers import Adam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVO7psINsmwF"},"source":["### Preprocessing variables\n","MODEL_BATCH_SIZE = 128\n","TOP_WORDS = vocab_size\n","MAX_POST_LENGTH = max_len\n","EMBEDDING_VECTOR_LENGTH = 40\n","\n","### Learning variables\n","LEARNING_RATE = 0.01\n","DROPOUT = 0.2\n","NUM_EPOCHS = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVdJNOG4KiUD"},"source":["model = Sequential()\n","model.add(\n","            Embedding(\n","                TOP_WORDS,\n","                EMBEDDING_VECTOR_LENGTH,\n","                input_length=MAX_POST_LENGTH,\n","                # weights=[embedding_matrix],\n","                mask_zero=True,\n","                trainable=True,\n","            )\n","        )\n","# model.add(SimpleRNN(EMBEDDING_VECTOR_LENGTH, dropout=DROPOUT, recurrent_dropout=DROPOUT, activation='sigmoid', kernel_initializer='zeros'))\n","# model.add(GRU(EMBEDDING_VECTOR_LENGTH, dropout=DROPOUT, recurrent_dropout=DROPOUT, activation='sigmoid', kernel_initializer='zeros'))\n","model.add(\n","            LSTM(\n","                EMBEDDING_VECTOR_LENGTH,\n","                dropout=DROPOUT,\n","                recurrent_dropout=DROPOUT,\n","                activation=\"sigmoid\",\n","                kernel_initializer=\"zeros\",\n","            )\n","        )\n","# model.add(Bidirectional(LSTM(EMBEDDING_VECTOR_LENGTH, dropout=DROPOUT, recurrent_dropout=DROPOUT, activation='sigmoid', kernel_initializer='zeros')))\n","model.add(Dense(1, activation=\"sigmoid\"))\n","optimizer = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n","mc = ModelCheckpoint('best_model2.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","model.compile(\n","            loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n","        )\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ey4wMmOZKiX5"},"source":["history=model.fit(\n","                    X_train,\n","                    y_train,\n","                    epochs=NUM_EPOCHS,\n","                    batch_size=MODEL_BATCH_SIZE,\n","                  callbacks=[es, mc],\n","                  validation_split=0.2\n","\n","                )\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQLNX-pQjgQb"},"source":["loaded_model2 = load_model('best_model2.h5')\n","predicted_version2=loaded_model2.predict(X_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQdN4FEbF_Kp"},"source":["p = []\n","for i in predicted_version2:\n","    if i >= 0.5:\n","        p.append(1)\n","    else:\n","        p.append(0)\n","print(classification_report(y_test, p, target_names=['class 0', 'class 1']))    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYdNL9-QrHL0"},"source":["z = []\n","for i in predicted_version2:\n","    z.append(np.argmax(i))\n","print(classification_report(y_test, z, target_names=['class 0', 'class 1']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOPSZxcTXfBk"},"source":[""],"execution_count":null,"outputs":[]}]}